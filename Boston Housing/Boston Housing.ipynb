{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing\n",
    "This is another popular dataset used in pattern recognition literature. The data set comes from the real estate industry in Boston (US). This is a regression problem. The data has 506 rows and 14 columns. Thus, it’s a fairly small data set where you can attempt any technique without worrying about your laptop’s memory being overused.\n",
    "<br>\n",
    "<br>\n",
    "<b>Problem:</b> Predict the median value of owner occupied homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from classifiers import KNearestNeighbor\n",
    "from classifiers import baseModel\n",
    "from classifiers import weightedKNN\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor for Classification\n",
    "The Dataset is fairly simple and small with no missing values. So we will not focus too much on Data Munging. Instead we will focus on building a KNN Classifier from scratch and running on this data. Now, since the Boston Housing is a regression problem and we want to build KNN for both Classification and Regression we will take another simple dataset for Classification - <b>the Wisconsin Breast Cancer data</b>.\n",
    "<br>\n",
    "<br>\n",
    "We will first build the KNN classifier for Classification task and run it on Breast Cancer data and check the accuracy. Next we will build the KNN classifier for Regression task and run it on the Boston Housing data. Finanlly I want to build one more flaver of KNN known as <b>Weighted KNN</b> and run it on Breast Cancer Data.\n",
    "<br>\n",
    "<br>\n",
    "The implementation of all these classifiers can be found in the <b>classifier.py</b> file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Breast_cancer_data = pd.read_csv('breast-cancer-wisconsin.data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Breast Cancer data doesn't need much pre-processing. Two operation we will do before we run on our classifier on it are:\n",
    "<br>\n",
    "1) We will drop the first column called 'ID'. \n",
    "<br>\n",
    "2)There are few missing values, shown as '?'. We will replace those with a value -99999. This is large number would make these values as outlier and hence they will not play any role in classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>uniform_cell_size</th>\n",
       "      <th>uniform_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clump_thickness  uniform_cell_size  uniform_cell_shape  marg_adhesion  \\\n",
       "0                5                  1                   1              1   \n",
       "1                5                  4                   4              5   \n",
       "2                3                  1                   1              1   \n",
       "3                6                  8                   8              1   \n",
       "4                4                  1                   1              3   \n",
       "\n",
       "   single_epith_cell_size  bare_nuclei  bland_chrom  normal_nucleoli  mitoses  \\\n",
       "0                       2            1            3                1        1   \n",
       "1                       7           10            3                2        1   \n",
       "2                       2            2            3                1        1   \n",
       "3                       3            4            3                7        1   \n",
       "4                       2            1            3                1        1   \n",
       "\n",
       "   class  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Breast_cancer_data.drop('ID',1,inplace=True)\n",
    "Breast_cancer_data.replace('?',-99999,inplace=True)\n",
    "Breast_cancer_data = Breast_cancer_data.apply(pd.to_numeric)\n",
    "Breast_cancer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will instentiate the KNN classifier and run it on the Breast Cancer data and check the accuracy we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN object instantiated\n"
     ]
    }
   ],
   "source": [
    "knn = KNearestNeighbor(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9785408\n"
     ]
    }
   ],
   "source": [
    "knn.fit(Breast_cancer_data)\n",
    "accuracy = knn.score_class(Breast_cancer_data)\n",
    "print(\"accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of 97% is great. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "Next we will load the Boston housing data. but instead of directly running it on the KNN classifier, we will first run it on a <b>Base Model</b>. This base mode does no learning. Instead it just retrun the mean value of the lable as prediction. It's always a good idea to build such a model and use it a benchmark. If the performance (RMSE in case of Regression) of the our classifier is better then that of the Base Model then we would know that we are moving in right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.09252</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>6.606</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>6.1899</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>383.779999</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>23.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.841</td>\n",
       "      <td>61.400002</td>\n",
       "      <td>3.3779</td>\n",
       "      <td>5</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>377.559998</td>\n",
       "      <td>11.410000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.13081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.713</td>\n",
       "      <td>94.099998</td>\n",
       "      <td>4.2330</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>360.170013</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>12.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>15.57570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>5.926</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>2.9084</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200001</td>\n",
       "      <td>368.739990</td>\n",
       "      <td>18.129999</td>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.49298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>6.635</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>3.3175</td>\n",
       "      <td>4</td>\n",
       "      <td>304</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>396.899994</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>22.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         crim    zn  indus  chas    nox     rm        age     dis  rad  tax  \\\n",
       "239   0.09252  30.0   4.93     0  0.428  6.606  42.200001  6.1899    6  300   \n",
       "36    0.09744   0.0   5.96     0  0.499  5.841  61.400002  3.3779    5  279   \n",
       "30    1.13081   0.0   8.14     0  0.538  5.713  94.099998  4.2330    4  307   \n",
       "468  15.57570   0.0  18.10     0  0.580  5.926  71.000000  2.9084   24  666   \n",
       "308   0.49298   0.0   9.90     0  0.544  6.635  82.500000  3.3175    4  304   \n",
       "\n",
       "       ptratio       black      lstat       medv  \n",
       "239  16.600000  383.779999   7.370000  23.299999  \n",
       "36   19.200001  377.559998  11.410000  20.000000  \n",
       "30   21.000000  360.170013  22.600000  12.700000  \n",
       "468  20.200001  368.739990  18.129999  19.100000  \n",
       "308  18.400000  396.899994   4.540000  22.799999  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.read_csv('boston.csv')\n",
    "boston_df = boston_df.apply(pd.to_numeric)\n",
    "boston_train,boston_test = train_test_split(boston_df,test_size =0.2)\n",
    "boston_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model object instantiated\n",
      "rmse_train [9.39836537]\n",
      "rmse_test [9.39836537]\n"
     ]
    }
   ],
   "source": [
    "baseMod = baseModel()\n",
    "baseMod.fit(boston_train)\n",
    "rmse_train = baseMod.score_reg(boston_train)\n",
    "rmse_test = baseMod.score_reg(boston_train)\n",
    "print('rmse_train',rmse_train)\n",
    "print('rmse_test',rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor for Regression\n",
    "<br>\n",
    "Now that we have the RMSE number for the base model, we will run the Boston housing data on the KNN classifier for Regression and compare the results with the Base Model. But before we do so let us normalize the features so that all of the feature values are between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hari_surender_sharma\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "min_val = boston_train['crim'].min()\n",
    "max_val = boston_train['crim'].max()\n",
    "boston_train['crim'] = (boston_train['crim']- min_val)/(max_val -min_val)\n",
    "boston_test['crim'] = (boston_test['crim']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['zn'].min()\n",
    "max_val = boston_train['zn'].max()\n",
    "boston_train['zn'] = (boston_train['zn']- min_val)/(max_val -min_val)\n",
    "boston_test['zn'] = (boston_test['zn']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['indus'].min()\n",
    "max_val = boston_train['indus'].max()\n",
    "boston_train['indus'] = (boston_train['indus']- min_val)/(max_val -min_val)\n",
    "boston_test['indus'] = (boston_test['indus']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['rm'].min()\n",
    "max_val = boston_train['rm'].max()\n",
    "boston_train['rm'] = (boston_train['rm']- min_val)/(max_val -min_val)\n",
    "boston_test['rm'] = (boston_test['rm']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['age'].min()\n",
    "max_val = boston_train['age'].max()\n",
    "boston_train['age'] = (boston_train['age']- min_val)/(max_val -min_val)\n",
    "boston_test['age'] = (boston_test['age']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['dis'].min()\n",
    "max_val = boston_train['dis'].max()\n",
    "boston_train['dis'] = (boston_train['dis']- min_val)/(max_val -min_val)\n",
    "boston_test['dis'] = (boston_test['dis']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['rad'].min()\n",
    "max_val = boston_train['rad'].max()\n",
    "boston_train['rad'] = (boston_train['rad']- min_val)/(max_val -min_val)\n",
    "boston_test['rad'] = (boston_test['rad']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['tax'].min()\n",
    "max_val = boston_train['tax'].max()\n",
    "boston_train['tax'] = (boston_train['tax']- min_val)/(max_val -min_val)\n",
    "boston_test['tax'] = (boston_test['tax']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['ptratio'].min()\n",
    "max_val = boston_train['ptratio'].max()\n",
    "boston_train['ptratio'] = (boston_train['ptratio']- min_val)/(max_val -min_val)\n",
    "boston_test['ptratio'] = (boston_test['ptratio']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['black'].min()\n",
    "max_val = boston_train['black'].max()\n",
    "boston_train['black'] = (boston_train['black']- min_val)/(max_val -min_val)\n",
    "boston_test['black'] = (boston_test['black']- min_val)/(max_val -min_val)\n",
    "\n",
    "min_val = boston_train['lstat'].min()\n",
    "max_val = boston_train['lstat'].max()\n",
    "boston_train['lstat'] = (boston_train['lstat']- min_val)/(max_val -min_val)\n",
    "boston_test['lstat'] = (boston_test['lstat']- min_val)/(max_val -min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048611</td>\n",
       "      <td>0.120124</td>\n",
       "      <td>0.387364</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>0.554613</td>\n",
       "      <td>0.524467</td>\n",
       "      <td>0.671651</td>\n",
       "      <td>0.244270</td>\n",
       "      <td>0.368704</td>\n",
       "      <td>0.418175</td>\n",
       "      <td>0.610149</td>\n",
       "      <td>0.895322</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>22.912624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.110542</td>\n",
       "      <td>0.241165</td>\n",
       "      <td>0.252302</td>\n",
       "      <td>0.266497</td>\n",
       "      <td>0.116180</td>\n",
       "      <td>0.137437</td>\n",
       "      <td>0.293247</td>\n",
       "      <td>0.192525</td>\n",
       "      <td>0.381925</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>0.236907</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.200523</td>\n",
       "      <td>9.410019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>0.446350</td>\n",
       "      <td>0.408342</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.171756</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.938777</td>\n",
       "      <td>0.143050</td>\n",
       "      <td>17.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.506611</td>\n",
       "      <td>0.770855</td>\n",
       "      <td>0.199602</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.984719</td>\n",
       "      <td>0.254043</td>\n",
       "      <td>21.650001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.049990</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625750</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.939238</td>\n",
       "      <td>0.371284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.418440</td>\n",
       "      <td>25.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     0.048611    0.120124    0.387364    0.076733    0.554613    0.524467   \n",
       "std      0.110542    0.241165    0.252302    0.266497    0.116180    0.137437   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.385000    0.000000   \n",
       "25%      0.001022    0.000000    0.169538    0.000000    0.448750    0.446350   \n",
       "50%      0.003465    0.000000    0.317632    0.000000    0.538000    0.506611   \n",
       "75%      0.049990    0.185000    0.646628    0.000000    0.625750    0.588427   \n",
       "max      1.000000    1.000000    1.000000    1.000000    0.871000    1.000000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     0.671651    0.244270    0.368704    0.418175    0.610149    0.895322   \n",
       "std      0.293247    0.192525    0.381925    0.322887    0.236907    0.231962   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.408342    0.087975    0.130435    0.171756    0.457447    0.938777   \n",
       "50%      0.770855    0.199602    0.173913    0.272901    0.659574    0.984719   \n",
       "75%      0.939238    0.371284    1.000000    0.914122    0.808511    0.996835   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  404.000000  404.000000  \n",
       "mean     0.301689   22.912624  \n",
       "std      0.200523    9.410019  \n",
       "min      0.000000    5.000000  \n",
       "25%      0.143050   17.275000  \n",
       "50%      0.254043   21.650001  \n",
       "75%      0.418440   25.525000  \n",
       "max      1.000000   50.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have build two options for measuring the distance between the quary point and neighboring point - <b>Euclidean distance</b> and <b> Manhattan distance</b>. We will use both these options and check RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using Euclidean distance\n",
      "rmse_train [3.09857266]\n",
      "rmse_test [3.84422591]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(boston_train)\n",
    "rmse_train = knn.score_reg(boston_train)\n",
    "rmse_test = knn.score_reg(boston_test)\n",
    "print('Performance using Euclidean distance')\n",
    "print('rmse_train',rmse_train)\n",
    "print('rmse_test',rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using manhattan distance\n",
      "rmse_train [3.02491446]\n",
      "rmse_test [3.59733477]\n"
     ]
    }
   ],
   "source": [
    "rmse_train = knn.score_reg(boston_train,dist_type='manhattan')\n",
    "rmse_test = knn.score_reg(boston_test,dist_type='manhattan')\n",
    "print('Performance using manhattan distance')\n",
    "print('rmse_train',rmse_train)\n",
    "print('rmse_test',rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is less then that of Base Model which means our classifier is definitely. Furthormore, The RMSE is more or less the same for distance measures we have used. So for this data either of the two can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted K Nearest Neighbor\n",
    "<br>\n",
    "The implementation of the Weighted KNN is done by referring to the method defined at below link:\n",
    "<br>\n",
    "https://epub.ub.uni-muenchen.de/1769/1/paper_399.pdf\n",
    "<br>\n",
    "<br>\n",
    "We have implemented two Kernal method <b> Gaussian </b> and <b>inversion</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted KNN object instantiated\n"
     ]
    }
   ],
   "source": [
    "wKNN = weightedKNN(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9756795\n"
     ]
    }
   ],
   "source": [
    "wKNN.fit(Breast_cancer_data)\n",
    "accuracy = wKNN.score_class(Breast_cancer_data,kernal='gauss')\n",
    "print(\"accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = wKNN.score_class(Breast_cancer_data,kernal='inversion')\n",
    "print(\"accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Kernal give acceptable perfromance on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
